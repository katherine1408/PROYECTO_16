

# ## Inicializaci√≥n

# In[1]:


import pandas as pd
import plotly.express as px 
import matplotlib.pyplot as plt
import seaborn as sns

from PIL import Image


# ## Carga los datos

# El conjunto de datos se almacena en la carpeta `/datasets/faces/` 
# - La carpeta `final_files` con 7600 fotos 
# - El archivo `labels.csv` con etiquetas, con dos columnas: `file_name` y `real_age` 
# Dado que el n√∫mero de archivos de im√°genes es bastante elevado, se recomienda evitar leerlos todos a la vez, ya que esto consumir√≠a muchos recursos computacionales. Te recomendamos crear un generador con ImageDataGenerator. Este m√©todo se explic√≥ en el cap√≠tulo 3, lecci√≥n 7 de este curso.
# 
# El archivo de etiqueta se puede cargar como un archivo CSV habitual.

# In[2]:


labels = pd.read_csv('/datasets/faces/labels.csv')


# ## EDA

# In[3]:


labels.info()


# In[4]:


labels.head()


# In[5]:


fig = plt.figure(figsize=(10, 10))
for i in range(12):
    fig.add_subplot(4, 3, i+1)
    plt.imshow(Image.open('/datasets/faces/final_files/' + labels['file_name'][i]))
    plt.title(f"{labels['real_age'][i]}")
    plt.xticks([])
    plt.yticks([])
    plt.tight_layout()


# In[6]:


num_samples = labels.shape[0]
age_distribution = labels['real_age'].describe()
age_counts = labels['real_age'].value_counts().sort_index()


# In[7]:


plt.figure(figsize=(10,5))
sns.histplot(labels['real_age'], bins=30, kde=True)
plt.xlabel("Edad")
plt.ylabel("Frecuencia")
plt.title("Distribuci√≥n de edades en el conjunto de datos")
plt.show()


# In[8]:


# Guardar hallazgos en un diccionario para referencia
hallazgos = {
    "N√∫mero total de muestras": num_samples,
    "Distribuci√≥n de edades": age_distribution.to_dict(),
    "Cantidad de edades √∫nicas": len(age_counts),
    "Edad m√≠nima": labels['real_age'].min(),
    "Edad m√°xima": labels['real_age'].max()
}
# Mostrar los resultados
hallazgos


# ### Conclusiones

# **Informaci√≥n del conjunto de datos:**
# 
# * Total de muestras : 7,591 im√°genes
# 
# *Distribuci√≥n de Edades:*
# 
# * Edad m√≠nima : 1 a√±o
# * Edad m√°xima : 100 a√±os
# * Edad promedio : 31 a√±os
# 
# *Distribuci√≥n por edades :*
# 
# * 25% de las im√°genes son de personas menores de 20 a√±os.  
# * 50% de las im√°genes tienen una edad menor o igual a 29 a√±os.  
# * 75% de las im√°genes tienen una edad menor o igual a 41 a√±os.  
# 
# **Gr√°fico de distribuci√≥n :   
# Se observa una mayor cantidad de im√°genes de personas entre 20 y 40 a√±os , pero tambi√©n hay representaci√≥n de edades menores y mayores.**

# <div class="alert alert-block alert-success">
# <b>Comentario del revisor (1ra Iteraci√≥n)</b> <a class="tocSkip"></a>
# 
# Excelente trabajo con el an√°lisis de tu dataset, siempre mant√©n esta buena pr√°ctica de redactar tu interpretaci√≥n y la conclusi√≥n del EDA, especialmente cuando se trate de im√°genes hay que mostrar ejemplos de las mismas para entender con lo que se trabajar√°
#     

# ## Modelado

# Define las funciones necesarias para entrenar tu modelo en la plataforma GPU y crea un solo script que las contenga todas junto con la secci√≥n de inicializaci√≥n.
# 
# Para facilitar esta tarea, puedes definirlas en este notebook y ejecutar un c√≥digo listo en la siguiente secci√≥n para componer autom√°ticamente el script.
# 
# Los revisores del proyecto tambi√©n verificar√°n las definiciones a continuaci√≥n, para que puedan comprender c√≥mo construiste el modelo.

# In[9]:


import pandas as pd

import tensorflow as tf

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.resnet import ResNet50
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten
from tensorflow.keras.optimizers import Adam


# In[10]:


def load_train(path):
    
    """
    Carga la parte de entrenamiento del conjunto de datos desde la ruta.
    """
    train_data_generator = ImageDataGenerator(rescale=1/255., validation_split=0.25)
    
    train_gen_flow = train_data_generator.flow_from_dataframe(
        labels,
        directory = '/dataset/faces/final_files/',
        x_col = 'file_name',
        y_col = 'real_age',
        target_size = (150,150),
        batch_size = 16,
        class_mode = 'raw',
        subset = 'training',
        seed = 617
    )
    # coloca tu c√≥digo aqu√≠

    return train_gen_flow
   


# In[11]:


def load_test(path):
    
    """
    Carga la parte de validaci√≥n/prueba del conjunto de datos desde la ruta
    """
    test_data_generator = ImageDataGenerator(rescale=1/255., validation_split=0.25)  # Normalizaci√≥n
    
    test_gen_flow = test_data_generator.flow_from_dataframe(
        labels,
        directory= '/dataset/faces/final_files/',
        x_col='file_name',
        y_col='real_age',
        target_size=(150, 150),
        batch_size=16,
        class_mode='raw',
        subset='test',  # Carga solo los datos de validaci√≥n
        seed=617
    )
    # coloca tu c√≥digo aqu√≠

    return test_gen_flow


# In[12]:


def create_model(input_shape):
    
    """
    Define el modelo
    """
    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(150, 150, 3))
    
    base_model.trainable = False  
    
    model = Sequential([
        base_model,
        GlobalAveragePooling2D(),  # Reduce dimensionalidad de la salida de ResNet50
        Dense(256, activation='relu'),  # Capa densa con 256 neuronas
        Dropout(0.5),  # Regularizaci√≥n para evitar sobreajuste
        Dense(1, activation='linear')  # Salida con activaci√≥n lineal para regresi√≥n de edad
    ])
    
    # Compilar el modelo
    model.compile(
        optimizer=Adam(learning_rate=0.0001),  # Optimizador Adam con LR ajustada
        loss='mean_squared_error',  # MSE para regresi√≥n
        metrics=['mae']  # Error absoluto medio como m√©trica principal
)
    
    
    # coloca tu c√≥digo aqu√≠

    return model


# In[15]:


def train_model(model, train_data, test_data, batch_size=None, epochs=20,
                steps_per_epoch=None, validation_steps=None):

    """
    Entrena el modelo dados los par√°metros
    """
    # Ajustar steps_per_epoch si no se proporciona
    if steps_per_epoch is None:
        steps_per_epoch = len(train_data) // train_data.batch_size

    # Ajustar validation_steps si no se proporciona
    if validation_steps is None:
        validation_steps = len(test_data) // test_data.batch_size
        
    # Entrenamiento del modelo
    history = model.fit(
        train_data,
        epochs=epochs,
        steps_per_epoch=steps_per_epoch,
        validation_data=test_data,
        validation_steps=validation_steps,
        verbose=1
    )
    
      # coloca tu c√≥digo aqu√≠
    return model




# ## Prepara el script para ejecutarlo en la plataforma GPU

# Una vez que hayas definido las funciones necesarias, puedes redactar un script para la plataforma GPU, descargarlo a trav√©s del men√∫ "File|Open..." (Archivo|Abrir) y cargarlo m√°s tarde para ejecutarlo en la plataforma GPU.
# 
# Nota: el script debe incluir tambi√©n la secci√≥n de inicializaci√≥n. A continuaci√≥n se muestra un ejemplo.

# In[14]:


# prepara un script para ejecutarlo en la plataforma GPU

init_str = """
import pandas as pd

import tensorflow as tf

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.resnet import ResNet50
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten
from tensorflow.keras.optimizers import Adam
"""

import inspect

with open('run_model_on_gpu.py', 'w') as f:
    
    f.write(init_str)
    f.write('\n\n')
        
    for fn_name in [load_train, load_test, create_model, train_model]:
        
        src = inspect.getsource(fn_name)
        f.write(src)
        f.write('\n\n')


# ### El resultado

# Coloca el resultado de la plataforma GPU como una celda Markdown aqu√≠.

# 1. Comportamiento de la P√©rdida
# La p√©rdida (Loss) y la p√©rdida en validaci√≥n (Val Loss) disminuyen constantemente, lo cual indica que el modelo est√° aprendiendo.
# Sin embargo, a partir de la √©poca 10-12 , la p√©rdida de entrenamiento sigue fluctuando, mientras que la de validaci√≥n se estabiliza.
# Esto puede indicar que el modelo est√° llegando a su capacidad √≥ptima de aprendizaje.
# 2. Comportamiento del MAE (Error Absoluto Medio)
# El MAE en entrenamiento y validaci√≥n disminuye constantemente, lo que es una buena se√±al .
# A partir de la √©poca 10-12 , el MAE de entrenamiento fluct√∫a m√°s , lo que puede indicar sobreajuste ( overfitting ).
# El MAE de validaci√≥n se estabiliza alrededor de 12 , lo que significa que el modelo tiene un error promedio de 12 a√±os en la predicci√≥n de edad .

# ## Conclusiones

# 
# ### üîπ **Configuraci√≥n del Entrenamiento**
# - **Modelo**: ResNet50 con capas adicionales para regresi√≥n de edad.
# - **Tama√±o de im√°genes**: 150x150 p√≠xeles.
# - **Optimizaci√≥n**: Adam (`learning_rate=0.0001`).
# - **√âpocas entrenadas**: 20.
# - **Batch Size**: 16.
# - **Conjunto de datos**: `Good Seed Dataset` (im√°genes de rostros con edades etiquetadas).
# - **Divisi√≥n de datos**: 75% entrenamiento, 25% validaci√≥n.
# 
# ---
# 
# ### üîπ **Resultados Finales**
# | M√©trica        | Entrenamiento | Validaci√≥n |
# |---------------|--------------|------------|
# | **Loss (MSE)** | 268.54        | 263.56      |
# | **Error Absoluto Medio (MAE)** | 12.83 a√±os  | 12.78 a√±os  |
# 
# üìâ **Observaciones**:
# - La **p√©rdida y el MAE disminuyeron progresivamente**, lo que indica que el modelo fue aprendiendo correctamente.
# - El **MAE final en validaci√≥n fue de 12.78 a√±os**, lo que sugiere que el modelo tiene un margen de error aceptable para la clasificaci√≥n de edad.
# - Se observa una ligera fluctuaci√≥n en las √∫ltimas √©pocas, lo que podr√≠a indicar un **leve sobreajuste**.
# 
# ---
# 
# ### üîπ **Interpretaci√≥n de los Resultados**
# ‚úÖ **El modelo basado en ResNet50 demostr√≥ ser efectivo para la estimaci√≥n de edad**, logrando un **error aceptable** en la predicci√≥n.  
# ‚úÖ El uso de **GPU aceler√≥ significativamente el entrenamiento**, permitiendo probar m√∫ltiples configuraciones en poco tiempo.  
# 
# üìå **Desaf√≠os detectados**:
# - **Sobreajuste leve**: La diferencia entre la p√©rdida en entrenamiento y validaci√≥n sugiere que el modelo memoriz√≥ parte del conjunto de entrenamiento.
# - **Datos desbalanceados**: La menor cantidad de ejemplos en edades extremas podr√≠a afectar la precisi√≥n del modelo en esos rangos.
# 
# ---
# 
# ### üîπ **Posibles Mejoras Futuras**
# üîπ **Optimizaci√≥n del Modelo**:
#    - Aplicar **Fine-Tuning** en las capas superiores de **ResNet50** para mejorar la precisi√≥n.
#    - Reducir la tasa de aprendizaje (`learning_rate=0.00005`) para evitar fluctuaciones en las √∫ltimas √©pocas.
#    - Utilizar un **Scheduler de Learning Rate** para ajustarlo din√°micamente durante el entrenamiento.
# 
# üîπ **Mejor Preprocesamiento de Datos**:
#    - **Balancear el conjunto de datos** con t√©cnicas de aumento de datos (Data Augmentation) en edades menos representadas.
#    - Aplicar **m√°s transformaciones** en las im√°genes para mejorar la generalizaci√≥n.
# 
# üîπ **Optimizaci√≥n del Entrenamiento**:
#    - Implementar **Early Stopping** para detener el entrenamiento cuando la p√©rdida de validaci√≥n deje de mejorar.
#    - Aumentar el n√∫mero de √©pocas a **30-40** si el modelo sigue aprendiendo sin sobreajustarse.
# 
# ---
# 
# ### **üìå Conclusi√≥n Final**
# ‚úÖ El modelo alcanz√≥ un **MAE de 12.78 a√±os en validaci√≥n**, lo que representa un margen de error moderado para determinar si una persona es menor de edad.  
# ‚úÖ **Con un ajuste de hiperpar√°metros y balanceo de datos, se podr√≠a reducir el margen de error** y mejorar la precisi√≥n del modelo.  
# üìå **Se recomienda optimizar el modelo y probar diferentes estrategias para mejorar su rendimiento en producci√≥n.**
# 
# ---
# 



# # Lista de control

# - [ ]  El Notebook estaba abierto 
# - [ ]  El c√≥digo no tiene errores
# - [ ]  Las celdas con el c√≥digo han sido colocadas en el orden de ejecuci√≥n
# - [ ]  Se realiz√≥ el an√°lisis exploratorio de datos 
# - [ ]  Los resultados del an√°lisis exploratorio de datos se presentan en el notebook final 
# - [ ]  El valor EAM del modelo no es superior a 8 
# - [ ]  El c√≥digo de entrenamiento del modelo se copi√≥ en el notebook final 
# - [ ]  El resultado de entrenamiento del modelo se copi√≥ en el notebook final 
# - [ ] Los hallazgos se proporcionaron con base en los resultados del entrenamiento del modelo

# In[ ]:




